<div class="container">
<img src="https://ichef.bbci.co.uk/news/660/cpsprodpb/151E5/production/_106410568_046383393-1.jpg" alt="Cinque Terre" width="1000" height="300">

<h1>
Challenges facing us today
</h1>

<p>
More than 180 human biases have been defined and classified, and any one of which can affect how we make decisions.
</p>

<p>
Biases find their way into the algorithm, and are used to make decisions by many, from governments to businesses.
</p>

<h3 class="color">
One of the cases here:
</h3>

<p class="color">
Joy Buolamwini created a data set using 1,270 photos of parliamentarians from three African nations and three Nordic countries.
The faces were selected to represent a broad range of human skin tones, using a labeling system developed by dermatologists, called the Fitzpatrick scale.
</p>

<p class="color">
1.The scale is viewed as more objective and precise than classifying based on race, according to the New York Times.
</p>

<p class="color">
2. Buolamwini found that when the person in the photo was a white man, the facial recognition software worked 99% of the time.
But when the photo was of a darker skinned woman, there was a nearly 35% error rate.
</p>

<p class="color">
3. For darker skinned men, their gender was misidentified roughly 12% of the time, while in a set of lighter skinned females, gender was misidentified about 7% of the time.
</p>


<p>
Bad data can contain implicit racial, gender, or ideological biases.
</p>

<p>
How to Reduce Unfair Discrimination in Algorithm? We believe that bias can be tamed and the we are eager to launch this learning tool.
</p>
</div>
